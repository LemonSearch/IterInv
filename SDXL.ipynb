{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-18 10:47:45,774] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f1a24381290>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from diffusers import StableDiffusionXLPipeline\n",
    "from pipelines.SDXL_pipeline import StableDiffusionXLPipeline\n",
    "# from pipelines.SDUP_pipeline import StableDiffusionUpscalePipeline\n",
    "# from pipelines.ddim_pipeline import StableDiffusionDDIMInvPipeline\n",
    "from diffusers.image_processor import VaeImageProcessor\n",
    "\n",
    "from diffusers.utils import pt_to_pil, numpy_to_pil\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import PIL\n",
    "image_processor=VaeImageProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home-local/kwang-local/miniconda3/envs/floydkai/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1353: FutureWarning: You are trying to load the model files of the `variant=fp32`, but no such modeling files are available.The default model files: {'text_encoder_2/pytorch_model.bin', 'vae/diffusion_pytorch_model.bin', 'text_encoder/model.safetensors', 'vae/diffusion_pytorch_model.safetensors', 'unet/diffusion_pytorch_model.safetensors', 'unet/diffusion_pytorch_model.bin', 'text_encoder/pytorch_model.bin', 'text_encoder_2/model.safetensors'} will be loaded instead. Make sure to not load from `variant=fp32`if such variant modeling files are not available. Doing so will lead to an error in v0.22.0 as defaulting to non-variantmodeling files is deprecated.\n",
      "  deprecate(\"no variant default\", \"0.22.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cba6e8858e64104bbc6b8077eb4d4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-0.9\", torch_dtype=torch.float32, variant=\"fp32\", use_safetensors=True\n",
    "    # \"stabilityai/stable-diffusion-xl-base-0.9\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "# pipe=pipe.to(\"cuda\")\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pth='images/cat_hq.jpg'\n",
    "\n",
    "_inv_raw_image = Image.open(img_pth).convert(\"RGB\").resize((1024,1024))\n",
    "inv_raw_image = image_processor.preprocess(_inv_raw_image)\n",
    "\n",
    "# image_ = image_processor.postprocess(inv_raw_image, output_type='pt')\n",
    "# inv_raw_image,inv_raw_image_ = pil_to_numpy_torch(_inv_raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### NOTE: 1,3,1024,1024. Scale -1,1. Pytorch Tensor\n",
    "# (inv_raw_image+1)/2\n",
    "# inv_raw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st stage compress and decompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.manual_seed(0)\n",
    "with torch.no_grad():\n",
    "    latent = pipe.prepare_image_latents(inv_raw_image.cuda(), 1, pipe.vae.dtype, 'cuda',generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk1/users/kwang-local/ctang/deepfloyd/pipelines/SDXL_pipeline.py:544: FutureWarning: The decode_latents method is deprecated and will be removed in a future version. Please use VaeImageProcessor instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # image_pt = pipe.decode_latents_pt(latent)\n",
    "    image = pipe.decode_latents(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((image_processor.denormalize(image_pt) - image_processor.denormalize(inv_raw_image))**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'SUXD.png'\n",
    "numpy_to_pil(image)[0].save(PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
